{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e73021",
   "metadata": {},
   "source": [
    "# Pre-lecture HW Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc3ea3d",
   "metadata": {},
   "source": [
    "The ability to quantify a notion and articulate it as a statement about a population parameter is a crucial aspect in evaluating whether or not it may be subjected to statistical analysis. A testable concept needs to be presented in a form that makes it possible to gather and analyze evidence in order to confirm or deny it. \n",
    "There are three main criterea that I would say make a good null hypothesis. Firstly, the hypothesis should make a claim concerning a population parameter. The null hypothesis can, for instance, claim that there is no population mean difference in blood pressure between the group receiving the new medication and the control group. Secondly, it should showcase the situation where there is \"no effect\" or \"no difference\". It frequently contradicts what scientists are trying to establish. Finally, it should be verifiable and tested. There has to be a means of gathering information that might lead to the null hypothesis being rejected.\n",
    "The main difference between the null hypothesis and the alternative hypothesis is that the null hypothesis states that there is no relationship, no effect, or no difference between the variables under investigation, it is the claim that we are looking for proof against. On the other hand, the alternative hypothesis contradicts the null hypothesis, proposing that there is an effect, difference, or relationship, it is typically the hypothesis the researcher is trying to support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6712b05a",
   "metadata": {},
   "source": [
    "# Pre-lecture HW Q2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e78db",
   "metadata": {},
   "source": [
    "If I was talking to a \"non-statistical\" audience, I would first define any terms that they wouldn't be familiar with in the context of data analysis.\n",
    "Population refers to the entire group you are interested in studying. Since studying an entire population is often impractical, we select a smaller, representative group called a sample. Parameter (μ) represents a numerical characteristic of the population. Statistic (x̄) is a numerical characteristic calculated from the sample. xi's represent the individual observations within a sample. Finally, μ0 refers to a specific value of the population parameter that is being tested in a hypothesis test.\n",
    "\n",
    "The statement implies that although we compute statistics (like x̄) from our sample, the purpose of statistical tests is to draw conclusions about the corresponding population characteristics (like μ). Even though we haven't measured every member of the population firsthand, we still utilize the sample data to make inferences about the full population. As a result, when a statistical test produces a result, it provides evidence to support a conclusion about the population parameter rather than merely supplying information about the particular sample we evaluated. For instance, we would consider a test's indication that a vaccine works well in our sample to be proof that the vaccine works well in the whole population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357de6f",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "● We began by examining a statement from a video you watched, emphasizing that the results of statistical tests pertain to population parameters, not merely sample statistics. This distinction is fundamental in statistical inference because we aim to draw conclusions about entire populations based on insights gleaned from smaller, representative samples.\n",
    "\n",
    "● To elucidate this concept for a non-statistical audience, we defined several key terms:\n",
    "\n",
    "○ A population encompasses the entire group we're interested in, while a sample represents a smaller subset selected from that population.\n",
    "\n",
    "○ A parameter quantifies a characteristic of the entire population (e.g., the average effectiveness of a drug for all individuals who could potentially benefit). In contrast, a statistic represents a numerical value calculated from a sample (e.g., the average effectiveness observed within our specific study group).\n",
    "\n",
    "○ The symbols xi's, x̄, μ, and u0 were also defined to denote individual observations within a sample, the sample mean, the population mean, and a specific value of the population parameter being tested, respectively.\n",
    "\n",
    "● Essentially, statistical tests bridge the gap between sample statistics and population parameters. We calculate statistics from our sample data, but our goal is to infer something meaningful about the corresponding population parameters.\n",
    "\n",
    "● So, when a statistical test suggests that a drug is effective based on our sample, we're not just making a statement about that particular sample. Instead, we're using that result as evidence to infer that the drug is likely effective in the broader population from which the sample was drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5717d2",
   "metadata": {},
   "source": [
    "# Pre-lecture HW Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e491d17",
   "metadata": {},
   "source": [
    "Because the p-value indicates the likelihood of observing our data, or data even more extreme than ours if the null hypothesis were true, we \"imagine a world where the null hypothesis is true\" in order to compute a p-value. This process helps us understand how unusual our data is under the assumption that the null hypothesis is true. For example, if the p-value is very small, it means that our observed data would be extremely unlikely if the null hypothesis were true. This might lead us to believe that the null hypothesis is not a good explanation for our data and we should instead consider the alternative hypothesis. On the other hand, if the p-value is large, it suggests that our data is fairly typical under the null hypothesis, and we don't have enough evidence to reject it. By \"imagining a world where the null hypothesis is true,\" we are essentially creating a standard against which to measure our real data. With the use of this benchmark, we may assess whether the observed results align with the expectations of the null hypothesis or are surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f765b4",
   "metadata": {},
   "source": [
    "# Pre-lecture HW Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28acb7c",
   "metadata": {},
   "source": [
    "The p-value represents the probability of getting data as extreme as the observed data, assuming the null hypothesis is true. A smaller p-value makes the null hypothesis look more ridiculous because it suggests that the observed data would be very unusual if the null hypothesis were actually true. For instance, if we obtain a p-value of 0.01, it means there's only a 1% chance of seeing our data (or more extreme data) if the null hypothesis were correct. When the observed data is highly unlikely under the assumption that the null hypothesis is true, it makes the null hypothesis look increasingly less plausible. In other words, the smaller the p-value, the more evidence we have against the null hypothesis, and the more ridiculous the null hypothesis will seem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c667a",
   "metadata": {},
   "source": [
    "# Pre-lecture HW Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55db3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated p-value: 0.0007\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Observed data\n",
    "observed_proportion = 80/124\n",
    "\n",
    "# Simulation parameters\n",
    "n_samples = 10000\n",
    "sample_size = 124\n",
    "\n",
    "# Simulate coin flips under the null hypothesis\n",
    "simulated_proportions = np.random.binomial(n=1, p=0.5, size=(n_samples, sample_size)).mean(axis=1)\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = np.sum(simulated_proportions >= observed_proportion) / n_samples\n",
    "\n",
    "print(\"Simulated p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6137ec0",
   "metadata": {},
   "source": [
    "I ran the simulation through the code provided to me by the chatbot a 10 times, and the simulated p-value ranges between 0.0001 and 0.001. This means that 0.001 ≥ p, which points to very strong evidence against the null hypothesis that the population doesn't have tilt tendencies. This suggests that for the sample statistic to have be 64.5% right tilt, there would have to be a tendency for people to tilt theie heads to the right. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f5186",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "You asked me to simulate a p-value for the observation that 64.5% of 124 kissing couples tilted their heads to the right. The null hypothesis was that there is no head-tilting preference in the population of kissing couples (i.e., a 50/50 split).\n",
    "I explained that we could simulate this by imagining a world where the null hypothesis was true, and simulating many samples (coin flips) of 124 couples each. We could then calculate the proportion of rightward tilts in each simulated sample and compare that to the observed proportion (64.5%). The p-value is the proportion of simulated proportions that are at least as extreme as the observed proportion. I then provided the code to carry out this simulation in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfa387",
   "metadata": {},
   "source": [
    "# Pre-lecture HW Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d06d97",
   "metadata": {},
   "source": [
    "Unless the p-value is zero after an extremely high number of samples, you cannot use a small p-value to definitively prove that the null hypothesis is false, or in the case of the second pre-lecture video, definitively prove that Fido is innocent or guilty using a p-value. Since the p-value is calculated by using the amount of samples, out of the thousands that you run, that produce a result similar or more extreme than your own, if the p-value is non-zero, that at least one of these samples yielded a result similar or more extreme than your own. This means that however unlikely it may be, it is still possible that the null hypothesis is true even with an extremely low p-value. Similarly, to be able to definitively conclude that the null hypothesis is true, the p-value would have to be equal to 0.1. If it is not, then it is still possible, however unlikely, that the null hypothesis is false even with an extremely high p-value. To conclude, the p-value would need to be zero or 0.1 with a very large sample size to be able to definitively conclude that the null hypothesis is true or false. Otherwise, we can only say that there is strong evidence that the null hypothesis is likely to be False with a small p-value, or that there is strong evidence that the null hypothesis is likely to be True with a large p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b2dde",
   "metadata": {},
   "source": [
    "# Pre-lecture HW Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "981b85b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Proportion: 0.51\n",
      "P-value (One-Tailed): 0.4653\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'health_scores' contains the difference in health scores \n",
    "# (post-vaccine minus pre-vaccine) for each patient\n",
    "health_scores = np.random.choice([-1, 1], size=100, p=[0.5, 0.5])\n",
    "\n",
    "# Calculate the observed proportion of patients with improved health\n",
    "observed_proportion = np.sum(health_scores > 0) / len(health_scores)\n",
    "\n",
    "# Set the number of simulations\n",
    "num_simulations = 10000\n",
    "\n",
    "# Simulate the sampling distribution under the null hypothesis (p=0.5)\n",
    "simulated_proportions = []\n",
    "for i in range(num_simulations):\n",
    "  simulated_scores = np.random.choice([-1, 1], size=len(health_scores), p=[0.5, 0.5])\n",
    "  simulated_proportion = np.sum(simulated_scores > 0) / len(simulated_scores)\n",
    "  simulated_proportions.append(simulated_proportion)\n",
    "\n",
    "# Calculate the p-value for a one-tailed test (improvement)\n",
    "p_value = np.sum(simulated_proportions >= observed_proportion) / num_simulations\n",
    "\n",
    "print(f\"Observed Proportion: {observed_proportion}\")\n",
    "print(f\"P-value (One-Tailed): {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae093e9",
   "metadata": {},
   "source": [
    "The original code for calculating the p-value likely resembled this structure:\n",
    "p_value = np.sum(abs(simulated_proportion - 0.5) >= abs(observed_proportion - 0.5)) / num_simulations\n",
    "This code calculates the p-value by considering simulated proportions that are both greater than and less than the observed proportion, as indicated by the use of the absolute value function (abs()) around both simulated_proportion - 0.5 and observed_proportion - 0.5.\n",
    "The new code provided by the Chatbot uses:\n",
    "p_value = np.sum(simulated_proportions >= observed_proportion) / num_simulations\n",
    "This code change ensures that you are only considering simulated proportions that are greater than or equal to the observed proportion (simulated_proportions >= observed_proportion), aligning with a one-tailed test for improvement.\n",
    "In essence, the main change in the code involves removing the absolute value function within the p-value calculation. This modification shifts the focus from extreme values in both directions to extreme values specifically in the direction of improvement, which is the core concept behind a one-tailed hypothesis test.\n",
    "\n",
    "The interpretation of a hypothesis test can be altered by changing from a two-tailed test to a one-tailed test. The original two-tailed test aimed to determine if there was any difference in patient health scores after the vaccine, regardless of whether the difference was positive or negative. The p-value calculated in this scenario represented the probability of observing a difference as extreme as the observed difference, in either direction, if the vaccine had no effect. The modified one-tailed test focuses on whether the vaccine led to an improvement in patient health, with the p-value representing the probability of observing a proportion of health improvement as extreme as the one in the data, assuming the vaccine has no real positive effect.\n",
    "\n",
    "Yes, we should expect a one-tailed test to have a smaller p-value compared to a two-tailed test because it focuses on a single direction of effect, examining whether the observed data is more extreme in the direction specified in the alternative hypothesis. Two-tailed tests consider both directions of effect, testing for any difference relative to the null hypothesis. The p-value is calculated from the area under the sampling distribution in the single tail corresponding to the direction of interest, while the two-tailed p-value is calculated from the combined area in both tails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c397dc4",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "You asked for the code for a one-tailed hypothesis test and an explanation of how the interpretation of a one-tailed test differs from a two-tailed test, along with how the p-values differ between the two.\n",
    "You were provided with Python code for conducting a one-tailed hypothesis test, specifically examining if a vaccine leads to an improvement in patient health scores. The provided code simulates a null hypothesis of no vaccine effect.\n",
    "The key change in the one-tailed code is the removal of the absolute value function in the p-value calculation, focusing on simulated proportions exceeding the observed proportion of improvement.\n",
    "The response explained that a one-tailed test focuses on the effect in a specific direction, resulting in a smaller p-value compared to a two-tailed test because it disregards the possibility of an effect in the opposite direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41a755",
   "metadata": {},
   "source": [
    "# Pre-lecture HW Q8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498cc481",
   "metadata": {},
   "source": [
    "I will be running an experiment to determine wether or not 80 students are able to correctly state if the tea that they are given was poured before or after the milk was poured. The experiment is based of the one that statistician Ronald Fisher peformed in which he gave his friend Muriel Bristol eight cups of tea, four with milk added in first and four with tea added in first, after she claimed that she could tell whether the milk was poured before or after her tea.\n",
    "\n",
    "Despite the experiment with STA130 students being based of Dr. Fisher's, there are many differences between the two. First of all, the sample size for the two experiment's are different. The experiment with STA130 students has a sample size of 80 students, whereas Dr. Fisher's experiment only has Dr. Fisher drinking eight cups of tea as the sample size. Second of all, the two experiments could possible have very different population behaviors. Dr. Bristol had tea regularily with Dr. Fisher, and likely had it without him too, meaning should would have been drnking quite a bit of tea, and would thus be extremely sensitive to the taste. On the other hand, in the experiment with STA130 students, it would be highly unlikely that any of the students would drink tea on as regular a basis as Dr. Fisher did, so they would likely react very differently to the taste of tea.\n",
    "\n",
    "Null Hypothesis ($H_0$): Students cannot tell the difference and randomly guess whether tea or milk was poured first, implying a 50% chance of guessing correctly.\n",
    "The Null Hypothesis states that the STA130 cannot tell the difference between tea with milk poured first and tea with milk last. As a result, the students would guess whether tea or milk was poured first,  which, since there are only 2 options, would give them a 50% chance of guessing correctly.\n",
    "\n",
    "Alternative Hypothesis ($H_A$): Students do not guess randomly, suggesting an ability to tell between the two options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba62e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed proportion of correct guesses: 0.6125\n",
      "P-value: 0.0291\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# make the analysis reproducible\n",
    "np.random.seed(1)\n",
    "\n",
    "# sample size of the experiment\n",
    "n_students = 80 \n",
    "# observed statistic: number of students who correctly identified the pouring order \n",
    "n_correct_guesses = 49 \n",
    "# observed test statistic: the proportion of correct guesses in the sample\n",
    "observed_proportion = n_correct_guesses / n_students \n",
    "# number of samples to simulate for the sampling distribution under the null hypothesis\n",
    "n_simulations = 10000\n",
    "simulated_proportions = np.random.binomial(n=n_students, p=0.5, size=n_simulations) / n_students \n",
    "# calculates the p-value as the proportion of simulated proportions that are as or more extreme than the observed proportion\n",
    "p_value = np.sum(simulated_proportions >= observed_proportion) / n_simulations \n",
    "\n",
    "print(f\"Observed proportion of correct guesses: {observed_proportion:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70014be",
   "metadata": {},
   "source": [
    "The null hypothesis regarding the population parameter of interest, in this case, the actual proportion of STA130 students who can correctly identify the pouring order of tea and milk, is evaluated by the code utilized in the tea experiment using the observed proportion of correct guesses (the test statistic). A p-value can be computed by  approximating the sampling distribution under the null hypothesis through simulation. Essentially, this method builds a reference point (the sampling distribution under the null hypothesis) through simulation, which we then compare to our observed data (the test statistic) to see if there is sufficient evidence to rule out the possibility that the observed results are the product of pure chance.\n",
    "\n",
    "A p-value of around 0.29, which is between 0.05 and 0.01 suggests that there is very little evidence that the null hypothesis is false. However, there is still some evidence that the null hypothesis might be false, meaning we can't conclusively say that the null hypothesis is True, or even to say that it is highly likely that the p-value is true.\n",
    "\n",
    "From the calculated p-value, we can conclude that it is likely that the students are able to tell the difference between tea with milk poured before and tea with milk poured after, and that they are not simply guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a992d",
   "metadata": {},
   "source": [
    "# Post-lecture HW Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce3029",
   "metadata": {},
   "source": [
    "Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
